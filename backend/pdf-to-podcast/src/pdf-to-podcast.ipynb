{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1cOIYTallhOXoVTl3RotZjmsRx51qPKUm","authorship_tag":"ABX9TyPfXiuCbm7xS3IIIfN4Mlor"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install PyPDF2 transformers pyttsx3 googletrans==4.0.0-rc1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4RnLCzH5cZLj","executionInfo":{"status":"ok","timestamp":1738360323994,"user_tz":-330,"elapsed":6652,"user":{"displayName":"nandini","userId":"17153866313679452712"}},"outputId":"0e974b96-be83-4e81-f44c-078365b0b4fc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n","Requirement already satisfied: pyttsx3 in /usr/local/lib/python3.11/dist-packages (2.98)\n","Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.11/dist-packages (4.0.0rc1)\n","Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.11/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.12.14)\n","Requirement already satisfied: hstspreload in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n","Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n","Requirement already satisfied: idna==2.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n","Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n","Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n","Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.11/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n","Requirement already satisfied: h2==3.* in /usr/local/lib/python3.11/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n","Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n","Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n"]}]},{"cell_type":"code","source":["!pip install tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04gcGNF_60S0","executionInfo":{"status":"ok","timestamp":1738360331637,"user_tz":-330,"elapsed":4731,"user":{"displayName":"nandini","userId":"17153866313679452712"}},"outputId":"385763b4-050d-48cd-ee2b-b7a9b56243b3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"]}]},{"cell_type":"code","source":["!pip install gtts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a6xWkm7kApp9","executionInfo":{"status":"ok","timestamp":1738360343672,"user_tz":-330,"elapsed":7189,"user":{"displayName":"nandini","userId":"17153866313679452712"}},"outputId":"91198aba-8342-4525-ebd8-5f7c195ea3e2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gtts in /usr/local/lib/python3.11/dist-packages (2.5.4)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gtts) (2.32.3)\n","Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gtts) (8.1.8)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2024.12.14)\n"]}]},{"cell_type":"code","source":["# Install required libraries\n","!pip install transformers torch soundfile datasets PyPDF2 googletrans==4.0.0-rc1\n","\n","import sys\n","import os\n","import re\n","import torch\n","import soundfile as sf\n","from PyPDF2 import PdfReader\n","from transformers import pipeline\n","from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n","from datasets import load_dataset\n","from googletrans import Translator\n","import numpy as np\n","from concurrent.futures import ThreadPoolExecutor\n","\n","# Set device (GPU if available, else CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Load models and datasets once (caching for reuse)\n","def load_models():\n","    \"\"\"Load and cache all models and datasets.\"\"\"\n","    print(\"Loading models...\")\n","    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0 if torch.cuda.is_available() else -1)\n","    processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n","    model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\").to(device)\n","    vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\").to(device)\n","    embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n","    translator = Translator()\n","    print(\"✓ Models loaded\")\n","    return summarizer, processor, model, vocoder, embeddings_dataset, translator\n","\n","# Load models and datasets globally\n","summarizer, processor, model, vocoder, embeddings_dataset, translator = load_models()\n","\n","def extract_text_from_pdf(pdf_path):\n","    \"\"\"Extract text from a PDF file.\"\"\"\n","    try:\n","        reader = PdfReader(pdf_path)\n","        text = \"\"\n","        for page in reader.pages:\n","            text += page.extract_text()\n","        return text.strip()\n","    except Exception as e:\n","        raise RuntimeError(f\"Failed to extract text from PDF: {str(e)}\")\n","\n","def preprocess_text(text):\n","    \"\"\"Clean and preprocess the text for better TTS output.\"\"\"\n","    # Remove special characters and symbols\n","    text = re.sub(r'[^\\w\\s.,!?]', '', text)\n","    # Replace multiple spaces with a single space\n","    text = re.sub(r'\\s+', ' ', text)\n","    return text.strip()\n","\n","def chunk_text(text, max_chars=600):\n","    \"\"\"Split text into smaller chunks for TTS processing.\"\"\"\n","    chunks = []\n","    current_chunk = \"\"\n","    for sentence in text.split(\". \"):  # Split by sentences\n","        if len(current_chunk) + len(sentence) + 2 <= max_chars:  # +2 for \". \"\n","            current_chunk += sentence + \". \"\n","        else:\n","            chunks.append(current_chunk.strip())\n","            current_chunk = sentence + \". \"\n","    if current_chunk:\n","        chunks.append(current_chunk.strip())\n","    return chunks\n","\n","def calculate_summary_length(input_length):\n","    \"\"\"Calculate appropriate max_length for summarization based on input length.\"\"\"\n","    # Aim for a summary that's about 40-60% of the input length\n","    max_length = max(30, min(int(input_length * 0.6), 130))\n","    min_length = max(20, int(max_length * 0.4))\n","    return max_length, min_length\n","\n","def summarize_text(text):\n","    \"\"\"Summarize text using a pre-trained model with dynamic length handling.\"\"\"\n","    if not text.strip():\n","        return \"No text content to summarize.\"\n","\n","    try:\n","        # Handle long texts by chunking and summarizing separately\n","        if len(text) > 1000:\n","            chunks = chunk_text(text)\n","            summaries = []\n","            for chunk in chunks:\n","                if chunk.strip():\n","                    # Calculate appropriate lengths for this chunk\n","                    input_length = len(chunk.split())\n","                    max_length, min_length = calculate_summary_length(input_length)\n","\n","                    summary = summarizer(chunk,\n","                                      max_length=max_length,\n","                                      min_length=min_length,\n","                                      do_sample=False,\n","                                      truncation=True)[0]['summary_text']\n","                    summaries.append(summary)\n","            return \" \".join(summaries)\n","        else:\n","            # Calculate appropriate lengths for the entire text\n","            input_length = len(text.split())\n","            max_length, min_length = calculate_summary_length(input_length)\n","\n","            summary = summarizer(text,\n","                               max_length=max_length,\n","                               min_length=min_length,\n","                               do_sample=False,\n","                               truncation=True)[0]['summary_text']\n","            return summary\n","    except Exception as e:\n","        raise RuntimeError(f\"Failed to summarize the text: {str(e)}\")\n","\n","def generate_voiceover(text, language='en'):\n","    \"\"\"Generate voiceover from text using a pre-trained TTS model from Hugging Face.\"\"\"\n","    if not text.strip():\n","        raise ValueError(\"No text provided for voiceover generation\")\n","\n","    # Preprocess the text\n","    text = preprocess_text(text)\n","    print(\"Processed Text for TTS:\", text)  # Debugging output\n","\n","    try:\n","        # Load a speaker embedding (e.g., for English)\n","        speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0).to(device)\n","\n","        # Split the text into smaller chunks\n","        chunks = chunk_text(text, max_chars=600)  # Increased chunk size\n","        print(f\"Number of chunks: {len(chunks)}\")  # Debugging output\n","\n","        # Generate speech for each chunk\n","        speech_chunks = []\n","        for i, chunk in enumerate(chunks):\n","            print(f\"Processing chunk {i + 1}/{len(chunks)}...\")\n","            inputs = processor(text=chunk, return_tensors=\"pt\", truncation=True, max_length=600)\n","            inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to the correct device\n","            with torch.no_grad():\n","                speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n","            speech_chunks.append(speech.cpu().numpy())\n","\n","        # Concatenate the speech chunks\n","        speech = np.concatenate(speech_chunks)\n","\n","        # Save the audio to a file\n","        sf.write(\"output.wav\", speech, samplerate=16000)\n","        print(\"✓ Voiceover generated using Hugging Face TTS model\")\n","    except Exception as e:\n","        raise RuntimeError(f\"Failed to generate voiceover: {str(e)}\")\n","\n","def translate_text(text, target_language='es'):\n","    \"\"\"Translate text to target language.\"\"\"\n","    if not text.strip():\n","        return text\n","\n","    try:\n","        translation = translator.translate(text, dest=target_language)\n","        return translation.text\n","    except Exception as e:\n","        raise RuntimeError(f\"Failed to translate text: {str(e)}\")\n","\n","def main():\n","    try:\n","        # Get inputs with better error handling\n","        pdf_path = input(\"Enter the path to the PDF file: \").strip('\"').strip()\n","        if not pdf_path:\n","            raise ValueError(\"PDF path cannot be empty\")\n","\n","        language_code = input(\"Enter the language code (e.g., 'en', 'es'): \").strip().lower()\n","        if not language_code:\n","            language_code = 'en'  # Default to English\n","\n","        # Validate PDF file\n","        if not os.path.isfile(pdf_path):\n","            raise ValueError(f\"The path '{pdf_path}' is not a valid file\")\n","        if not pdf_path.lower().endswith('.pdf'):\n","            raise ValueError(f\"The file '{pdf_path}' is not a PDF file\")\n","\n","        # Process the PDF\n","        print(\"\\nProcessing PDF...\")\n","        extracted_text = extract_text_from_pdf(pdf_path)\n","        print(\"✓ Text extraction complete\")\n","        print(\"Extracted Text Preview:\", extracted_text[:500])  # Debugging output\n","\n","        print(\"\\nGenerating summary...\")\n","        summary = summarize_text(extracted_text)\n","        print(\"✓ Summary complete:\")\n","        print(\"-\" * 50)\n","        print(summary)\n","        print(\"-\" * 50)\n","\n","        # Handle translation if needed\n","        if language_code != 'en':\n","            print(f\"\\nTranslating to {language_code}...\")\n","            summary = translate_text(summary, language_code)\n","            print(\"✓ Translation complete:\")\n","            print(\"-\" * 50)\n","            print(summary)\n","            print(\"-\" * 50)\n","\n","        print(\"\\nGenerating audio...\")\n","        generate_voiceover(summary, language_code)\n","        print(\"✓ Audio generation complete - saved as 'output.wav'\")\n","\n","    except Exception as e:\n","        print(f\"\\nError: {str(e)}\")\n","        sys.exit(1)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nAdJLb4qY2aQ","executionInfo":{"status":"ok","timestamp":1738361233169,"user_tz":-330,"elapsed":255631,"user":{"displayName":"nandini","userId":"17153866313679452712"}},"outputId":"3e13ab19-464b-45cb-bfdb-1753b05d46b0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n","Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n","Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.11/dist-packages (4.0.0rc1)\n","Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.11/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.12.14)\n","Requirement already satisfied: hstspreload in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n","Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n","Requirement already satisfied: idna==2.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n","Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n","Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n","Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.11/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n","Requirement already satisfied: h2==3.* in /usr/local/lib/python3.11/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n","Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n","Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.9.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Using device: cuda\n","Loading models...\n"]},{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]},{"name":"stdout","output_type":"stream","text":["✓ Models loaded\n","Enter the path to the PDF file: /content/drive/MyDrive/MINeD-Hackathon-Cactus-Project/backend/MINeD Hackathon/Sample PDFs/Addressing_the_Productivity_Paradox_in_Healthcare_with_Retrieval_Augmented_Generative_AI_Chatbots.pdf\n","Enter the language code (e.g., 'en', 'es'): en\n"]},{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Processing PDF...\n","✓ Text extraction complete\n","Extracted Text Preview: Addressing the Productivity Paradox in Healthcare\n","with Retrieval Augmented Generative AI Chatbots\n","Sajani Ranasinghe∗, Daswin De Silva∗, Nishan Mills∗,\n","Damminda Alahakoon∗, Milos Manic‡, Yen Lim†, Weranja Ranasinghe†\n","∗Centre for Data Analytics and Cognition, La Trobe University, Melbourne, Australia\n","†Department of Urology, Monash Health, Melbourne, Australia\n","‡Department of Computer Science, Virginia Commonwealth University, Richmond, USA\n","Abstract —Artificial Intelligence (AI) is reshaping the hea\n","\n","Generating summary...\n"]},{"output_type":"stream","name":"stderr","text":["Your max_length is set to 30, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"]},{"output_type":"stream","name":"stdout","text":["✓ Summary complete:\n","--------------------------------------------------\n","Artificial Intelligence (AI) is reshaping the health-care landscape through diverse innovations, personalisations and decision-making capabilities. Addressing the Productivity Paradox in Healthcare with Retrieval Aug The human-like intelligence of Gen-erative AI has been fundamental in driving this transformation. Despite large investments and some early successes, several studies have signalled the emergence of a productivity paradox. We present the Retrieval Augmented GenerativeAI Chatbot framework for consultation summaries, diagnostic insights, and emotional assessments of patients. We further demonstrate the technical value of this framework in Generative Artificial Intelligence (AI) is transforming healthcare. It is leading a paradigm shift in the application of AI across its spectrum of functions. State-of-the-art models have introduced innovativeappro Genera-tesquetive AI is not without significant limitations. It has demonstrated advanced conversational abilities in healthcare. Generative AI models are known to fabricate information in its naive effort to provide a response to every query. Vague prompts, staticparametric knowledge, limited domain expertise, insufficient training data,  productivity paradox is pre-existing at the intersection between technology and healthcare. It is defined as the decrease in workplace pro-ductivity despite an increase in technology investment In addressing the case of productivity paradox in GenerativeAI, RAG represents an effective approach. RAG diverges from the use of raw LLMs or their fine-tuning with task-specific data. R AG can be used to bridge the gap between advanced AI and practical, efficient medical service delivery. There is an escalating interest in AI agents that can leverage generative AI and LLMs. In this study, we present the design and development of a Retrieval Augmented Generative AI Chatbot framework. These agents are capable of performing various tasks with The RAG archi-tecture allows for the enrichment of results using GenerativeAI models. We further demonstrate the technical value of this framework in service innovation, 2024 IEEE International Conference on Industrial Technology (ICIT) | 979-8-3503-4026-6/24/$31.00 ©20 24 IEEE | DOI: 10. The proposed framework is depicted in Fig 1. The frame-work begins with data streams and datasets received from the pre-existing data module. The framework introduces three analysis mod-                ules for patient telehealth conversation summarisation, This framework enables medical practitioners to make general inquiries and access patient infor-                mation enriched with analytical insights. The end-users of this system,                the healthcare professionals can interact with this platform through a chatbot Data is amalgamated from validated and reliable sources including publications, clinical trials, and observational studies. The unstructured data includes transcribed patient con-                versations resulting from telehealth consultations Structured data com-prises the patient’s Electronic Health Record (EHR) data, including demographics, biomarkers, medical and treatmenthistories, diagnostic details, medications, and other related  LLMs can summarise complex medical discussions into concise notes. There is existing evidence of the use of LLMs such as GPT-4 for biomedical knowledge curation. This study explores a self-verification framework with LLMs such as GPT-4 for efficient extraction of patient information from healthcare texts. LangChain is a robust framework for developing applications using LLMs. LangChain successfullyovercomes the issue of limited token size by introducing ap-proaches like ‘Stuff’, � LangChain summarisation module. GPT-3.5-turbo or Claude 2 can be leveraged for enhanced performance. module is adept at extracting and highlighting key aspects. BioBERT is anadaptation of BERT (Bidirectional Encoder Representations) model. Spark NLP an open-source text processing library leverages LLMs for advanced Disease diagnosis and assessment supports healthcare pro-fessionals in early disease detection, allowing for treatment tailored to the patient’s unique needs. This module A recent study demonstrates the ability of GPT-3 to diag-nose medical conditions nearly as accurately as physicians. Such a strategy not only increases the effectiveness of treatment but also improves survival rates and reduces the likelihood of side effects. Researchers at GoogleResearch and DeepMind have developed Med-PaLM 2. It produced an accuracy over 80% answering benchmark medical questions. In this module, we analyze the patient’s consultation history. Unsupervised methods like clustering algorithms and Self-Organizing Maps (SOMs) will be applied to detect patterns, anomalies, and clusters in disease detection. transformer models will also be employed to enhance disease Evaluating feature importance with methods like SHAP (SHapley Additive exPlanations) is crucial for understanding the impact of each attribute on model predictions. This evaluation helps end users comprehend Emotion detection module supports clinicians to understand and address complex emotional states of patients. ‘Chatcounselor’ is a specialised LLM  AI-based emotion model is designed for adaptability, allowing fine-tuning to suit various scenarios. The model has demonstrated significant applicability and value in the healthcare domain. This model alsopossesses the capability to discern emotion intensities and isadept at managing negations. Research has extended to identify complex emotional states such as depression, anxiety and stress in conversations. Our work will be expanded to encompass not just thevariants of eight primary emotions evoked during tele We will be using a lexicon drivenapproach to define similar words associated with each emotion. Executing this emotion model will facilitate the generation of emotion profiles at conversation and patient level. Emotion profiles can be created at a multi-granular level. Efforts are in progress to test the feasibility of emotion detection using few-shot learningtechniques. Transitions are crucial, as they can be employedin real-time to alleviate patient distress. They serve as a basis for evaluation metrics The RAG architecture initiates with data loading and trans-formation component. We will analyse the emotion Timeline at the patient level. This will provide insights into the patient’s overall well-being. The data and data from the three analysis components are imported. They undergo a transformation process to be broken down into manageable segments. The effectiveness of the system relies heavily on In information retrieval, when the user initiates a query, it gets transformed into an embedding representation. The vector store is searched to find pertinent information based on semanticsimilarity. The information retrieved is further enhanced by LangChain and LlamaIndex are two robust frameworks that facilitate the implementation of RAG. LangChain specialises in conver-                sational retrieval agents that are fine-tuned for engaging in conversations. In the design of the retrieval agent, we are experimenting with OpenAI ChatModels such as GPT-3.5-turbo. After retrieving the information, it Fig 2 illustrates the process by which healthcare profes-sionals can obtain a patient summary using the unique patientID. The dataset is part of a larger project with cancer care providers. This summary encapsulates information about the patient’s diseases, treatments, side effects, and con-cerns, providing valuable insights for healthcare professionals to act upon. In the scenario depicted in Fig The XGBoost model, with the highest F1 score of 93.02%, was selected for its superior performance. It can also provide SHAP featureimportance values, The consultant has the capability to inquire about the patient’s emotional and mental health status through the Conversational agent. The positive emotions identified are happiness, hopefulness/optimism, surprise, and mistrust Emotion algebra can be used to detect signs of anxiety, depression, and suicidal ideation. The professional can access these emotion profiles on either a call-specific or patient-specific basis. Having access to emotion transition profiles at both the call and patient levels equips telehealth consultants with valuable information. These timelines display the patient’s emotional changes over time. In this study, we have presented the the design and de-velopment of a Retrieval Augmented Generative AI Chat-bot framework for healthcare. The framework We demonstrated the capabilities of this framework in providing an improved healthcare service and addressing the challenges of the productivity paradox. RAG AI chatbot has the potential to address the productivity                paradox by improving the efficiency of information processing and decision-making. As future work, we plan to integrate a diverse array of multi-modal data, including images, We intend to conduct a field test of the framework in an actual clinical setting leading to further confirmation and validity of its capabilities. Chatgpt and generative ai guidelines for addressing academic integrity and augmenting pre-existing chatbots will be published in 2023. The study was published in the Australasian Journal of Information Systems. The researchers hope to use big data analytics to improve the accuracy of diabetes screening. Empathicconversational agents for real-time monitoring and co-facilitation ofpatient-centered healthcare. A medical chat model fine-tuned on llama model using medical domain knowledge. ‘Chatdoctor’ could be used to help people with health care decisions. P. Jennings, “Augmenting industrial chatbots in energy systems using chatgpt generative ai,” in 2023 IEEE 32nd InternationalSymposium on Industrial Electronics (ISIE) . IEEE, 2023, pp. 1– “Artificial intelligence chatbots will revolutionize how cancer patients. access information: Chatgpt represents a paradigm-shift,” JNCI CancerSpectrum , vol. 7, no. 2, p. pkad010, 2023. The future landscape of large language models for biomedical knowledge extraction is described in a new study. The study, published in the journal Communications Medicine, is based on a case study on adverse drug events. Bert is a pre-trained biomedical language representation model for biomedical text mining. The model can be used to train text-mining systems. Spark nlp: Natural language understanding at scale,” Software Impacts , p. 100058, 2021. Theories of emotion were developed by R. Plutchik in the 1980s. Theory of emotion is based on a general psychoevolutionary theory of emotion. A large language models for mental health support have been proposed. Machine learning to support social media empowered patients in cancer care and treatment decisions, according to a new study. The research was presented at the 15th International Conference on Human System Interaction (HSI) in 2022. The research was conducted using deep learning. “Langchain,” https://www.langchain.com/, 2022-10, accessed: 2023-11-16. H. Moraliyage, D. De Silva, W. Ranasinghe A. Adikari, D. De Silva, and X. Yu, “A cognitivemodel for emotion awareness in industrial chatbots,” in 2019 IEEE. “17th international conference on industrial informatics (INDIN) , Authorized licensed use limited to: Nirma University Institute of Technology. Downloaded on January 30,2025 at 10:54\n","--------------------------------------------------\n","\n","Generating audio...\n","Processed Text for TTS: Artificial Intelligence AI is reshaping the healthcare landscape through diverse innovations, personalisations and decisionmaking capabilities. Addressing the Productivity Paradox in Healthcare with Retrieval Aug The humanlike intelligence of Generative AI has been fundamental in driving this transformation. Despite large investments and some early successes, several studies have signalled the emergence of a productivity paradox. We present the Retrieval Augmented GenerativeAI Chatbot framework for consultation summaries, diagnostic insights, and emotional assessments of patients. We further demonstrate the technical value of this framework in Generative Artificial Intelligence AI is transforming healthcare. It is leading a paradigm shift in the application of AI across its spectrum of functions. Stateoftheart models have introduced innovativeappro Generatesquetive AI is not without significant limitations. It has demonstrated advanced conversational abilities in healthcare. Generative AI models are known to fabricate information in its naive effort to provide a response to every query. Vague prompts, staticparametric knowledge, limited domain expertise, insufficient training data, productivity paradox is preexisting at the intersection between technology and healthcare. It is defined as the decrease in workplace productivity despite an increase in technology investment In addressing the case of productivity paradox in GenerativeAI, RAG represents an effective approach. RAG diverges from the use of raw LLMs or their finetuning with taskspecific data. R AG can be used to bridge the gap between advanced AI and practical, efficient medical service delivery. There is an escalating interest in AI agents that can leverage generative AI and LLMs. In this study, we present the design and development of a Retrieval Augmented Generative AI Chatbot framework. These agents are capable of performing various tasks with The RAG architecture allows for the enrichment of results using GenerativeAI models. We further demonstrate the technical value of this framework in service innovation, 2024 IEEE International Conference on Industrial Technology ICIT 97983503402662431.00 20 24 IEEE DOI 10. The proposed framework is depicted in Fig 1. The framework begins with data streams and datasets received from the preexisting data module. The framework introduces three analysis mod ules for patient telehealth conversation summarisation, This framework enables medical practitioners to make general inquiries and access patient infor mation enriched with analytical insights. The endusers of this system, the healthcare professionals can interact with this platform through a chatbot Data is amalgamated from validated and reliable sources including publications, clinical trials, and observational studies. The unstructured data includes transcribed patient con versations resulting from telehealth consultations Structured data comprises the patients Electronic Health Record EHR data, including demographics, biomarkers, medical and treatmenthistories, diagnostic details, medications, and other related LLMs can summarise complex medical discussions into concise notes. There is existing evidence of the use of LLMs such as GPT4 for biomedical knowledge curation. This study explores a selfverification framework with LLMs such as GPT4 for efficient extraction of patient information from healthcare texts. LangChain is a robust framework for developing applications using LLMs. LangChain successfullyovercomes the issue of limited token size by introducing approaches like Stuff, LangChain summarisation module. GPT3.5turbo or Claude 2 can be leveraged for enhanced performance. module is adept at extracting and highlighting key aspects. BioBERT is anadaptation of BERT Bidirectional Encoder Representations model. Spark NLP an opensource text processing library leverages LLMs for advanced Disease diagnosis and assessment supports healthcare professionals in early disease detection, allowing for treatment tailored to the patients unique needs. This module A recent study demonstrates the ability of GPT3 to diagnose medical conditions nearly as accurately as physicians. Such a strategy not only increases the effectiveness of treatment but also improves survival rates and reduces the likelihood of side effects. Researchers at GoogleResearch and DeepMind have developed MedPaLM 2. It produced an accuracy over 80 answering benchmark medical questions. In this module, we analyze the patients consultation history. Unsupervised methods like clustering algorithms and SelfOrganizing Maps SOMs will be applied to detect patterns, anomalies, and clusters in disease detection. transformer models will also be employed to enhance disease Evaluating feature importance with methods like SHAP SHapley Additive exPlanations is crucial for understanding the impact of each attribute on model predictions. This evaluation helps end users comprehend Emotion detection module supports clinicians to understand and address complex emotional states of patients. Chatcounselor is a specialised LLM AIbased emotion model is designed for adaptability, allowing finetuning to suit various scenarios. The model has demonstrated significant applicability and value in the healthcare domain. This model alsopossesses the capability to discern emotion intensities and isadept at managing negations. Research has extended to identify complex emotional states such as depression, anxiety and stress in conversations. Our work will be expanded to encompass not just thevariants of eight primary emotions evoked during tele We will be using a lexicon drivenapproach to define similar words associated with each emotion. Executing this emotion model will facilitate the generation of emotion profiles at conversation and patient level. Emotion profiles can be created at a multigranular level. Efforts are in progress to test the feasibility of emotion detection using fewshot learningtechniques. Transitions are crucial, as they can be employedin realtime to alleviate patient distress. They serve as a basis for evaluation metrics The RAG architecture initiates with data loading and transformation component. We will analyse the emotion Timeline at the patient level. This will provide insights into the patients overall wellbeing. The data and data from the three analysis components are imported. They undergo a transformation process to be broken down into manageable segments. The effectiveness of the system relies heavily on In information retrieval, when the user initiates a query, it gets transformed into an embedding representation. The vector store is searched to find pertinent information based on semanticsimilarity. The information retrieved is further enhanced by LangChain and LlamaIndex are two robust frameworks that facilitate the implementation of RAG. LangChain specialises in conver sational retrieval agents that are finetuned for engaging in conversations. In the design of the retrieval agent, we are experimenting with OpenAI ChatModels such as GPT3.5turbo. After retrieving the information, it Fig 2 illustrates the process by which healthcare professionals can obtain a patient summary using the unique patientID. The dataset is part of a larger project with cancer care providers. This summary encapsulates information about the patients diseases, treatments, side effects, and concerns, providing valuable insights for healthcare professionals to act upon. In the scenario depicted in Fig The XGBoost model, with the highest F1 score of 93.02, was selected for its superior performance. It can also provide SHAP featureimportance values, The consultant has the capability to inquire about the patients emotional and mental health status through the Conversational agent. The positive emotions identified are happiness, hopefulnessoptimism, surprise, and mistrust Emotion algebra can be used to detect signs of anxiety, depression, and suicidal ideation. The professional can access these emotion profiles on either a callspecific or patientspecific basis. Having access to emotion transition profiles at both the call and patient levels equips telehealth consultants with valuable information. These timelines display the patients emotional changes over time. In this study, we have presented the the design and development of a Retrieval Augmented Generative AI Chatbot framework for healthcare. The framework We demonstrated the capabilities of this framework in providing an improved healthcare service and addressing the challenges of the productivity paradox. RAG AI chatbot has the potential to address the productivity paradox by improving the efficiency of information processing and decisionmaking. As future work, we plan to integrate a diverse array of multimodal data, including images, We intend to conduct a field test of the framework in an actual clinical setting leading to further confirmation and validity of its capabilities. Chatgpt and generative ai guidelines for addressing academic integrity and augmenting preexisting chatbots will be published in 2023. The study was published in the Australasian Journal of Information Systems. The researchers hope to use big data analytics to improve the accuracy of diabetes screening. Empathicconversational agents for realtime monitoring and cofacilitation ofpatientcentered healthcare. A medical chat model finetuned on llama model using medical domain knowledge. Chatdoctor could be used to help people with health care decisions. P. Jennings, Augmenting industrial chatbots in energy systems using chatgpt generative ai, in 2023 IEEE 32nd InternationalSymposium on Industrial Electronics ISIE . IEEE, 2023, pp. 1 Artificial intelligence chatbots will revolutionize how cancer patients. access information Chatgpt represents a paradigmshift, JNCI CancerSpectrum , vol. 7, no. 2, p. pkad010, 2023. The future landscape of large language models for biomedical knowledge extraction is described in a new study. The study, published in the journal Communications Medicine, is based on a case study on adverse drug events. Bert is a pretrained biomedical language representation model for biomedical text mining. The model can be used to train textmining systems. Spark nlp Natural language understanding at scale, Software Impacts , p. 100058, 2021. Theories of emotion were developed by R. Plutchik in the 1980s. Theory of emotion is based on a general psychoevolutionary theory of emotion. A large language models for mental health support have been proposed. Machine learning to support social media empowered patients in cancer care and treatment decisions, according to a new study. The research was presented at the 15th International Conference on Human System Interaction HSI in 2022. The research was conducted using deep learning. Langchain, httpswww.langchain.com, 202210, accessed 20231116. H. Moraliyage, D. De Silva, W. Ranasinghe A. Adikari, D. De Silva, and X. Yu, A cognitivemodel for emotion awareness in industrial chatbots, in 2019 IEEE. 17th international conference on industrial informatics INDIN , Authorized licensed use limited to Nirma University Institute of Technology. Downloaded on January 30,2025 at 1054\n","Number of chunks: 21\n","Processing chunk 1/21...\n","Processing chunk 2/21...\n","Processing chunk 3/21...\n","Processing chunk 4/21...\n","Processing chunk 5/21...\n","Processing chunk 6/21...\n","Processing chunk 7/21...\n","Processing chunk 8/21...\n","Processing chunk 9/21...\n","Processing chunk 10/21...\n","Processing chunk 11/21...\n","Processing chunk 12/21...\n","Processing chunk 13/21...\n","Processing chunk 14/21...\n","Processing chunk 15/21...\n","Processing chunk 16/21...\n","Processing chunk 17/21...\n","Processing chunk 18/21...\n","Processing chunk 19/21...\n","Processing chunk 20/21...\n","Processing chunk 21/21...\n","✓ Voiceover generated using Hugging Face TTS model\n","✓ Audio generation complete - saved as 'output.wav'\n"]}]}]}